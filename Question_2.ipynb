{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be55eb4",
   "metadata": {},
   "source": [
    "## For gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847d1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10426db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Chargement des données\n",
    "df = pd.read_csv('celldata.csv')\n",
    "\n",
    "# Séparer la cible (Y) et les variables explicatives (X)\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "## 2. Définition des Catégories de Variables\n",
    "# Variables numériques continues \n",
    "numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'Salary']\n",
    "\n",
    "# Variables catégorielles nominales \n",
    "categorical_features = ['Geography', 'Gender']\n",
    "\n",
    "# Variables binaires déjà bianires \n",
    "binary_features = ['HasCrCard', 'IsActiveMember']\n",
    "\n",
    "\n",
    "## 3. Création du Préprocesseur \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # 1. Standardisation pour les variables numériques\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        \n",
    "        # 2. Encodage One-Hot pour les variables catégorielles\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        \n",
    "        # 3. Passer les variables binaires directement\n",
    "        ('bin', 'passthrough', binary_features)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386f7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du Pipeline\n",
    "# Utilise la technique de gradient boosting pour construire une forêt d'arbres.\n",
    "gbm_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', GradientBoostingClassifier(\n",
    "                                   n_estimators=100, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth=3, \n",
    "                                   random_state=42))])\n",
    "\n",
    "# Entraînement\n",
    "gbm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred_gbm = gbm_pipeline.predict(X_test)\n",
    "y_proba_gbm = gbm_pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7819848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Préparation des Données pour l'Analyse d'Équité ---\n",
    "\n",
    "# X_test est la DataFrame non transformée utilisée pour la prédiction\n",
    "gender_test = X_test['Gender'].reset_index(drop=True)\n",
    "\n",
    "# y_test et y_pred_gbm (prédictions binaires du Gradient Boosting) sont utilisés ici\n",
    "equity_df = pd.DataFrame({\n",
    "    'Gender': gender_test,\n",
    "    'True_Churn': y_test.reset_index(drop=True),\n",
    "    'Predicted_Churn': y_pred_gbm \n",
    "})\n",
    "\n",
    "results_female = equity_df[equity_df['Gender'] == 'Female']\n",
    "results_male = equity_df[equity_df['Gender'] == 'Male']\n",
    "\n",
    "# --- 2. Fonctions de Calcul des Taux ---\n",
    "\n",
    "def calculate_rates(data):\n",
    "    \"\"\"Calcule le taux de Churn prédit, le Recall et la Precision pour un sous-groupe.\"\"\"\n",
    "    \n",
    "    # Évite les erreurs si le sous-groupe est vide\n",
    "    if data.empty:\n",
    "        return {'Pred_Rate': np.nan, 'Recall': np.nan, 'Precision': np.nan}\n",
    "    \n",
    "    # Taux de prédiction de Churn (pour l'Indépendance)\n",
    "    pred_rate = data['Predicted_Churn'].mean() \n",
    "    \n",
    "    # Recall (pour la Séparation)\n",
    "    # Gère le cas où il n'y a pas de Churn réel dans le groupe (évite division par zéro)\n",
    "    if data['True_Churn'].sum() > 0:\n",
    "        recall = recall_score(data['True_Churn'], data['Predicted_Churn'])\n",
    "    else:\n",
    "        recall = np.nan\n",
    "        \n",
    "    # Precision (pour la Suffisance)\n",
    "    # Gère le cas où il n'y a pas de Churn prédit dans le groupe\n",
    "    if data['Predicted_Churn'].sum() > 0:\n",
    "        precision = precision_score(data['True_Churn'], data['Predicted_Churn'])\n",
    "    else:\n",
    "        precision = np.nan\n",
    "        \n",
    "    return {'Pred_Rate': pred_rate, 'Recall': recall, 'Precision': precision}\n",
    "\n",
    "# Calcul des métriques pour chaque groupe\n",
    "metrics_female = calculate_rates(results_female)\n",
    "metrics_male = calculate_rates(results_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d1937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "=== RÉSULTATS DE L'ANALYSE D'ÉQUITÉ (Gender) - GBM ===\n",
      "=====================================================\n",
      "Nombre de Femmes : 1064\n",
      "Nombre d'Hommes : 1336\n",
      "-------------------------------------------------------\n",
      "A. CRITÈRE D'INDÉPENDANCE (Parité Démographique)\n",
      "  Taux de prédiction de Churn (P(Ŷ=1|A)) :\n",
      "  > Femmes : 0.1438\n",
      "  > Hommes : 0.0921\n",
      "  DIFFÉRENCE ABSOLUE : 0.0517\n",
      "  -> INTERPRÉTATION : Le critère est VIOLÉ. Le modèle cible un genre plus que l'autre.\n",
      "-------------------------------------------------------\n",
      "B. CRITÈRE DE SÉPARATION (Égalité des Chances / Recall)\n",
      "  Rappel (Recall) - Taux de détection du Churn réel :\n",
      "  > Femmes : 0.4585\n",
      "  > Hommes : 0.4563\n",
      "  DIFFÉRENCE ABSOLUE : 0.0022\n",
      "  -> INTERPRÉTATION : Le critère est RAPPROCHÉ. Le modèle est également bon pour détecter le Churn dans les deux groupes.\n",
      "-------------------------------------------------------\n",
      "C. CRITÈRE DE SUFFISANCE (Égalité des Prédictions / Precision)\n",
      "  Précision (Precision) - Fiabilité des prédictions de Churn :\n",
      "  > Femmes : 0.8301\n",
      "  > Hommes : 0.7642\n",
      "  DIFFÉRENCE ABSOLUE : 0.0658\n",
      "  -> INTERPRÉTATION : Le critère est RAPPROCHÉ. Les prédictions de Churn sont d'une fiabilité similaire pour les deux groupes.\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================================================\")\n",
    "print(\"=== RÉSULTATS DE L'ANALYSE D'ÉQUITÉ (Gender) - GBM ===\")\n",
    "print(\"=====================================================\")\n",
    "\n",
    "# --- Affichage des Métriques de Base ---\n",
    "print(f\"Nombre de Femmes : {len(results_female)}\")\n",
    "print(f\"Nombre d'Hommes : {len(results_male)}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "# --- A. Critère d'Indépendance (Independence) - P(Ŷ=1|A) ---\n",
    "print(\"A. CRITÈRE D'INDÉPENDANCE (Parité Démographique)\")\n",
    "print(\"  Taux de prédiction de Churn (P(Ŷ=1|A)) :\")\n",
    "print(f\"  > Femmes : {metrics_female['Pred_Rate']:.4f}\")\n",
    "print(f\"  > Hommes : {metrics_male['Pred_Rate']:.4f}\")\n",
    "\n",
    "diff_pred_rate = abs(metrics_female['Pred_Rate'] - metrics_male['Pred_Rate'])\n",
    "\n",
    "print(f\"  DIFFÉRENCE ABSOLUE : {diff_pred_rate:.4f}\")\n",
    "\n",
    "if diff_pred_rate < 0.05: # Utilisation d'un seuil arbitraire de 5% pour l'évaluation\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est RAPPROCHÉ. Le modèle prédit des taux de Churn similaires.\")\n",
    "else:\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est VIOLÉ. Le modèle cible un genre plus que l'autre.\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "# --- B. Critère de Séparation (Separation) - P(Ŷ=1|Y=1, A) ---\n",
    "print(\"B. CRITÈRE DE SÉPARATION (Égalité des Chances / Recall)\")\n",
    "print(\"  Rappel (Recall) - Taux de détection du Churn réel :\")\n",
    "print(f\"  > Femmes : {metrics_female['Recall']:.4f}\")\n",
    "print(f\"  > Hommes : {metrics_male['Recall']:.4f}\")\n",
    "\n",
    "diff_recall = abs(metrics_female['Recall'] - metrics_male['Recall'])\n",
    "\n",
    "print(f\"  DIFFÉRENCE ABSOLUE : {diff_recall:.4f}\")\n",
    "\n",
    "if diff_recall < 0.10: # Utilisation d'un seuil arbitraire de 10% pour l'évaluation\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est RAPPROCHÉ. Le modèle est également bon pour détecter le Churn dans les deux groupes.\")\n",
    "elif metrics_female['Recall'] < metrics_male['Recall']:\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est VIOLÉ. Le modèle est moins performant pour détecter le Churn chez les Femmes.\")\n",
    "else:\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est VIOLÉ. Le modèle est moins performant pour détecter le Churn chez les Hommes.\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "# --- C. Critère de Suffisance (Sufficiency) - P(Y=1|Ŷ=1, A) ---\n",
    "print(\"C. CRITÈRE DE SUFFISANCE (Égalité des Prédictions / Precision)\")\n",
    "print(\"  Précision (Precision) - Fiabilité des prédictions de Churn :\")\n",
    "print(f\"  > Femmes : {metrics_female['Precision']:.4f}\")\n",
    "print(f\"  > Hommes : {metrics_male['Precision']:.4f}\")\n",
    "\n",
    "diff_precision = abs(metrics_female['Precision'] - metrics_male['Precision'])\n",
    "\n",
    "print(f\"  DIFFÉRENCE ABSOLUE : {diff_precision:.4f}\")\n",
    "\n",
    "if diff_precision < 0.10: # Utilisation d'un seuil arbitraire de 10% pour l'évaluation\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est RAPPROCHÉ. Les prédictions de Churn sont d'une fiabilité similaire pour les deux groupes.\")\n",
    "elif metrics_female['Precision'] < metrics_male['Precision']:\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est VIOLÉ. Les prédictions de Churn pour les Femmes sont moins fiables (plus de faux positifs).\")\n",
    "else:\n",
    "    print(\"  -> INTERPRÉTATION : Le critère est VIOLÉ. Les prédictions de Churn pour les Hommes sont moins fiables (plus de faux positifs).\")\n",
    "\n",
    "print(\"=====================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
